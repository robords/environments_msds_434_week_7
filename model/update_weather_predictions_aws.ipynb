{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e08d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8adc4",
   "metadata": {},
   "source": [
    "# Cost Predictions on AWS\n",
    "\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ce.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a59e0",
   "metadata": {},
   "source": [
    "## Get the Most Recently Updated File Key from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e821ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'raw-weather-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f75cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_year_key_from_s3(bucket):\n",
    "    '''\n",
    "    Here, we get the most recent file from s3, and then get the date from it\n",
    "    '''\n",
    "    # Here's the URIs\n",
    "    path_names = ['SNOW', 'PRCP', 'SNWD', 'TMAX', 'TMIN']\n",
    "    \n",
    "    current_year = datetime.now().year\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    element_key_dict = {}\n",
    "    for item in path_names:\n",
    "        response = s3.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            Prefix=item # this is somewhat arbitrary, but we just need to pick a path\n",
    "        )\n",
    "        key = [i['Key'] for i in response['Contents'] if str(current_year) in\n",
    "              i['Key']][0]\n",
    "        \n",
    "        element_key_dict[item] = key\n",
    "    return element_key_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84245da",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "342dd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class weather_forecast:\n",
    "    \n",
    "    def __init__(self, s3_path, retrain, element, import_job_name,\n",
    "                forecast_horizon, forecast_frequency, predictor_name,\n",
    "                forecast_name):\n",
    "        \n",
    "        self.s3_path = s3_path\n",
    "        self.role = boto3.client('iam').get_role(RoleName='ForecastNotebookRole')\n",
    "        self.role_arn = self.role['Role']['Arn']\n",
    "        \n",
    "        self.client = boto3.client('forecast')\n",
    "        \n",
    "        if element == 'Snow':\n",
    "            self.dataset_name = 'Weather_Predictions_Time_Series_MSDS_434'\n",
    "        else:\n",
    "            self.dataset_name = f'Weather_Predictions_Time_Series_{element}'\n",
    "        self.dataset_arn = self.create_dataset()\n",
    "        \n",
    "        while self.check_status('dataset') != 'ACTIVE':\n",
    "            t.sleep(60)\n",
    "            self.check_status('dataset')\n",
    "            \n",
    "        self.import_job_name = import_job_name\n",
    "        self.dataset_import_job_arn = self.import_dataset()\n",
    "        \n",
    "        self.dataset_group_name = f'{element}_Forecast'\n",
    "        self.dataset_group_arn = self.dataset_group()\n",
    "        \n",
    "        while self.check_status('import') != 'ACTIVE':\n",
    "            t.sleep(60)\n",
    "            self.check_status('import')\n",
    "        \n",
    "        self.forecast_name = forecast_name\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.forecast_frequency = forecast_frequency\n",
    "        self.retrain = True\n",
    "        if self.retrain == True:\n",
    "            max_predictor_updatetime = max(([item['LastModificationTime'] for item in \n",
    "                                 client.list_predictors()['Predictors'] \n",
    "                                 if element.lower() in item['PredictorName'].lower()]))\n",
    "\n",
    "            old_predictor_arn = ([item for item in client.list_predictors()['Predictors'] \n",
    "                                  if max_predictor_updatetime == item['LastModificationTime']])\n",
    "            self.retrainedPredictorName = predictor_name\n",
    "            self.referencePredictorArn = old_predictor_arn[0]['PredictorArn']\n",
    "        else:\n",
    "            self.predictor_name = predictor_name\n",
    "        self.predictor_arn = self.train_predictor()\n",
    "        \n",
    "        while self.check_status('predictor') != 'ACTIVE':\n",
    "            t.sleep(60)\n",
    "            self.check_status('predictor')\n",
    "        \n",
    "        self.forecast = forecast_name\n",
    "        self.forecast_arn = self.create_forecast()\n",
    "        \n",
    "    \n",
    "    def create_dataset(self):\n",
    "        dataset_dicts = self.client.list_datasets()['Datasets']\n",
    "\n",
    "        if self.dataset_name in [i['DatasetName'] for i in self.client.list_datasets()['Datasets']]:\n",
    "            print('Dataset Already Exists')\n",
    "            ts_dataset_arn = ([item for item in dataset_dicts if \n",
    "                               item[\"DatasetName\"] == self.dataset_name][0]['DatasetArn'])\n",
    "        else:\n",
    "            print('Creating New Dataset')\n",
    "            schema = {\n",
    "               \"Attributes\":[\n",
    "                  {\n",
    "                     \"AttributeName\":\"timestamp\",\n",
    "                     \"AttributeType\":\"timestamp\"\n",
    "                  },\n",
    "                  {\n",
    "                     \"AttributeName\":\"target_value\",\n",
    "                     \"AttributeType\":\"float\"\n",
    "                  },\n",
    "                  {\n",
    "                     \"AttributeName\":\"item_id\",\n",
    "                     \"AttributeType\":\"string\"\n",
    "                  }\n",
    "               ]\n",
    "            }\n",
    "\n",
    "            # check if the dataset is created first:\n",
    "\n",
    "            create_dataset_response = self.client.create_dataset(\n",
    "                DatasetName=self.dataset_name,\n",
    "                Domain='CUSTOM',\n",
    "                DatasetType='TARGET_TIME_SERIES',\n",
    "                DataFrequency='1D',\n",
    "                Schema=schema\n",
    "            )\n",
    "            ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "            print('Dataset Create Initiated')\n",
    "        \n",
    "        return ts_dataset_arn\n",
    "    \n",
    "    def import_dataset(self):\n",
    "        TIMESTAMP_FORMAT = \"yyyy-MM-dd\"\n",
    "        TIMEZONE = \"UTC\"\n",
    "\n",
    "        import_job = self.client.list_dataset_import_jobs(\n",
    "            Filters=[\n",
    "                {\n",
    "                    'Key': 'DatasetArn',\n",
    "                    'Value': self.dataset_arn,\n",
    "                    'Condition': 'IS'\n",
    "                },\n",
    "            ]\n",
    "        )   \n",
    "\n",
    "        if self.import_job_name in [i['DatasetImportJobName'] for i in import_job['DatasetImportJobs']]:\n",
    "            print('Already Exists')\n",
    "            ts_dataset_import_job_arn = [item for item in import_job['DatasetImportJobs'] if item[\"DatasetImportJobName\"] == self.import_job_name][0]['DatasetImportJobArn']\n",
    "        else:\n",
    "            ts_dataset_import_job_response = \\\n",
    "                self.client.create_dataset_import_job(DatasetImportJobName=self.import_job_name,\n",
    "                                                   DatasetArn=self.dataset_arn,\n",
    "                                                   DataSource= {\n",
    "                                                     \"S3Config\" : {\n",
    "                                                         \"Path\": self.s3_path,\n",
    "                                                         \"RoleArn\": self.role_arn\n",
    "                                                     } \n",
    "                                                   },\n",
    "                                                   TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                                   TimeZone = TIMEZONE)\n",
    "\n",
    "            ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "            describe_dataset_import_job_response = self.client.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "            print(f\"Waiting for Dataset Import Job with ARN to become ACTIVE. This process could take 5-10 minutes.\")\n",
    "        return ts_dataset_import_job_arn\n",
    "    \n",
    "    def dataset_group(self):\n",
    "        DATASET_ARNS = [self.dataset_arn]\n",
    "        \n",
    "        if self.dataset_group_name in [i['DatasetGroupName'] for i in self.client.list_dataset_groups()['DatasetGroups']]:\n",
    "            print('Already Exists')\n",
    "            dataset_group_arn = ([item for item in self.client.list_dataset_groups()['DatasetGroups'] \n",
    "                                 if item[\"DatasetGroupName\"] == self.dataset_group_name][0]['DatasetGroupArn'])\n",
    "        else:\n",
    "            create_dataset_group_response = \\\n",
    "                self.client.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                              DatasetGroupName=self.dataset_group_name,\n",
    "                                              DatasetArns=DATASET_ARNS)\n",
    "\n",
    "            dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "            describe_dataset_group_response = self.client.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "\n",
    "            print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")\n",
    "    \n",
    "        return dataset_group_arn\n",
    "    \n",
    "    def train_predictor(self):\n",
    "        if self.retrain == True:\n",
    "            create_auto_predictor_response=self.client.create_auto_predictor(\n",
    "                PredictorName=self.retrainedPredictorName, \n",
    "                ReferencePredictorArn=self.referencePredictorArn)\n",
    "            predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "        else:\n",
    "            if self.predictor_name in [i['PredictorName'] for i in self.client.list_predictors()['Predictors']]:\n",
    "                print('Already Exists')\n",
    "                predictor_arn = ([item for item in self.client.list_predictors()['Predictors'] \n",
    "                                     if item[\"PredictorName\"] == self.predictor_name][0]['PredictorArn'])\n",
    "            else:\n",
    "                create_auto_predictor_response = \\\n",
    "                    self.client.create_auto_predictor(PredictorName = self.predictor_name,\n",
    "                                                   ForecastHorizon = self.forecast_horizon,\n",
    "                                                   ForecastFrequency = self.forecast_frequency,\n",
    "                                                   DataConfig = {\n",
    "                                                       'DatasetGroupArn': self.dataset_group_arn\n",
    "                                                    })\n",
    "\n",
    "                predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "                print(f\"Waiting for Predictor with ARN to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE\")\n",
    "        return predictor_arn\n",
    "    \n",
    "    def create_forecast(self):\n",
    "        \n",
    "        if self.forecast_name in [i['ForecastName'] for i in self.client.list_forecasts()['Forecasts']]:\n",
    "            print('Already Exists')\n",
    "            forecast_arn = ([item for item in self.client.list_forecasts()['Forecasts'] \n",
    "                                 if item[\"ForecastName\"] == self.forecast_name][0]['ForecastArn'])\n",
    "        else:\n",
    "\n",
    "            create_forecast_response = \\\n",
    "                self.client.create_forecast(ForecastName=self.forecast_name,\n",
    "                                         PredictorArn=self.predictor_arn)\n",
    "\n",
    "            forecast_arn = create_forecast_response['ForecastArn']\n",
    "            print(f\"Waiting for Forecast to become ACTIVE. Depending on data size and predictor settings，it can take several hours to be ACTIVE.\")\n",
    "\n",
    "        return forecast_arn\n",
    "    \n",
    "    def check_status(self, describe_type):\n",
    "        if describe_type == 'dataset':\n",
    "            describe_dataset_response = self.client.describe_dataset(DatasetArn=self.dataset_arn)\n",
    "            print(f\"The Dataset is now {describe_dataset_response['Status']}.\")\n",
    "            return describe_dataset_response['Status']\n",
    "        \n",
    "        elif describe_type == 'import':\n",
    "            status = self.client.describe_dataset_import_job(DatasetImportJobArn=self.dataset_import_job_arn)\n",
    "            print(status['DatasetImportJobName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {status[\"Status\"]}')\n",
    "            return status[\"Status\"]\n",
    "        \n",
    "        elif describe_type == 'predictor':\n",
    "            pred_status = self.client.describe_auto_predictor(PredictorArn=self.predictor_arn)\n",
    "            print(pred_status['PredictorName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {pred_status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {pred_status[\"Status\"]}')\n",
    "            return pred_status[\"Status\"]\n",
    "        \n",
    "        elif describe_type == 'forecast':\n",
    "            forecast_status = self.client.describe_forecast(ForecastArn=self.forecast_arn)\n",
    "            print(forecast_status['ForecastName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {forecast_status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {forecast_status[\"Status\"]}')\n",
    "            \n",
    "            return forecast_status[\"Status\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efe7470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = get_current_year_key_from_s3(bucket)['SNOW']\n",
    "element = 'Snow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4840173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://raw-weather-data/SNOW'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_path = f's3://{bucket}/{element.upper()}'\n",
    "s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39cf6a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Already Exists\n",
      "The Dataset is now ACTIVE.\n",
      "Waiting for Dataset Import Job with ARNto become ACTIVE. This process could take 5-10 minutes.\n",
      "Already Exists\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Status: CREATE_PENDING\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 30\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 30\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 29\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 29\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 28\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 28\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 27\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 27\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 26\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 26\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 25\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 25\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 24\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 24\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 23\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 23\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 22\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 22\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 21\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 21\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 20\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 20\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 19\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 19\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 18\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 18\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 17\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 17\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 16\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 16\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 15\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Time Remaining in Minutes (estimated): 15\n",
      "Status: CREATE_IN_PROGRESS\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Status: ACTIVE\n",
      "Weather_New_Import_2022_11_20_15_43\n",
      "Status: ACTIVE\n",
      "Snow_Predictor_2022_11_20_15_43\n",
      "Status: CREATE_PENDING\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clear_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/jwjlxbrd1r7cyt0248jmvr_wjk7k6g/T/ipykernel_25914/1717855176.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0mforecast_horizon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      \u001b[0mforecast_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SNOW_FORECAST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                      predictor_name = f\"Snow_Predictor_{datetime.now().strftime('%Y_%m_%d_%H_%M')}\",)\n\u001b[0m",
      "\u001b[0;32m/var/folders/mc/jwjlxbrd1r7cyt0248jmvr_wjk7k6g/T/ipykernel_25914/4242821472.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, s3_path, retrain, element, import_job_name, forecast_horizon, forecast_frequency, predictor_name, forecast_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictor'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ACTIVE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
     ]
    }
   ],
   "source": [
    "forecast_output = weather_forecast(s3_path = s3_path, retrain = True, element = element,\n",
    "                                    import_job_name = f\"Weather_New_Import_{datetime.now().strftime('%Y_%m_%d_%H_%M')}\",\n",
    "                                     forecast_horizon = 180, forecast_frequency = \"1D\", \n",
    "                                     forecast_name = \"SNOW_FORECAST\", \n",
    "                                     predictor_name = f\"Snow_Predictor_{datetime.now().strftime('%Y_%m_%d_%H_%M')}\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f506b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
