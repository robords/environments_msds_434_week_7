{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d84daf3-8c3f-4478-af58-c051dee7f3ce",
   "metadata": {},
   "source": [
    "# Weather Predictions on AWS Autopilot with NOAA Data\n",
    "\n",
    "https://docs.opendata.aws/noaa-ghcn-pds/readme.html\n",
    "\n",
    "Get the data from public S3 and copy it to my new bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed7ab519-49ab-4f48-a268-311e08676008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://noaa-ghcn-pds/ghcnd-stations.txt to weather/ghcnd-stations.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# get and cleanup the stations file\n",
    "aws s3 cp s3://noaa-ghcn-pds/ghcnd-stations.txt ./weather/ghcnd-stations.txt \n",
    "python3 stations_cleanup.py\n",
    "\n",
    "# upload it\n",
    "aws s3 cp ./weather/stations.csv s3://raw-weather-data/ghcnd-stations.csv\n",
    "\n",
    "# Clean up the temp files and directory\n",
    "rm ./weather/ghcnd-stations.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653d949-f8ff-4efe-b1a2-1e7d8d647209",
   "metadata": {},
   "source": [
    "Let's try to only generate files for the five core elements:\n",
    "\n",
    "* PRCP = Precipitation (tenths of mm)\n",
    "* SNOW = Snowfall (mm)\n",
    "* SNWD = Snow depth (mm)\n",
    "* TMAX = Maximum temperature (tenths of degrees C)\n",
    "* TMIN = Minimum temperature (tenths of degrees C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ff86b3-2e3a-4543-880c-840ae6e3ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://noaa-ghcn-pds/csv.gz/2020.csv.gz to weather/2020.csv.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "for VARIABLE in 2020; do\n",
    "    # Get the file\n",
    "    aws s3 cp s3://noaa-ghcn-pds/csv.gz/\"$VARIABLE\".csv.gz ./weather/\"$VARIABLE\".csv.gz\n",
    "    # Decompress the zip file into a temp directory\n",
    "    gzip -d ./weather/\"$VARIABLE\".csv.gz\n",
    "    # Add headers\n",
    "    { echo 'id,date,element,value,M-FLAG,Q-FLAG,S-FLAG,OBS-TIME'; cat ./weather/\"$VARIABLE\".csv; } > ./weather/\"$VARIABLE\"_with_headers.csv\n",
    "    # filter out the columns with bad data\n",
    "    awk -F '\",\"'  'BEGIN {OFS=\",\"} { if ((toupper($6) == \"\"))  print }' ./weather/\"$VARIABLE\"_with_headers.csv > ./weather/\"$VARIABLE\"_filtered.csv\n",
    "    # create a separate file for each value in the third column\n",
    "    awk -v year=$VARIABLE -F ',' '{print >> (\"./weather/\" year \"/\" $3 \".csv\")}' ./weather/\"$VARIABLE\"_filtered.csv\n",
    "    # Combine the stations data in and add headers back to the remaining files\n",
    "    for ELEMENT in PRCP SNOW SNWD TMAX TMIN; do\n",
    "        {\n",
    "            join -t, <(sort ./weather/\"$VARIABLE\"/\"$ELEMENT\".csv) <(sed 1d ./weather/stations.csv | sort)\n",
    "        } > ./weather/\"$VARIABLE\"/\"$ELEMENT\"_combined.csv\n",
    "        { \n",
    "            echo 'id,date,element,value,M-FLAG,Q-FLAG,S-FLAG,OBS-TIME,state'; cat ./weather/\"$VARIABLE\"/\"$ELEMENT\"_combined.csv; \n",
    "        } > ./weather/\"$VARIABLE\"/\"$ELEMENT\"_with_headers.csv\n",
    "        # Sync up the contents of the temp directory to S3 prefix\n",
    "        aws s3 cp ./weather/\"$VARIABLE\"/\"$ELEMENT\"_with_headers.csv s3://raw-weather-data/\"$ELEMENT\"/\"$VARIABLE\".csv\n",
    "    done\n",
    "    # delete all files except those with _with_headers.csv\n",
    "    ls -d -1 \"$PWD/weather/$VARIABLE/\"*.* | egrep -v \"_with_headers.csv\" | xargs rm\n",
    "    # Clean up the temp files and directory\n",
    "    rm ./weather/\"$VARIABLE\"_with_headers.csv ./weather/\"$VARIABLE\".csv*\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0189118-e878-45bb-ac49-7603f0e70668",
   "metadata": {},
   "source": [
    "## Combine the stations data in with each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a7e54b-4bad-4ee5-8a30-daa2e17b74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#awk -F '\",\"'  'BEGIN {OFS=\",\"} { if (toupper($6) == \"NaN\" && $3 ~ /^WT/)  print }' ./weather/2022_with_headers.csv > ./weather/2022_with_headers_filtered.csv\n",
    "_2020 = pd.read_csv('./weather/2020_filtered.csv', nrows=1000)\n",
    "stations = pd.read_csv('./weather/stations.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "122d7f00-0489-484b-a7dd-50cb2d7fb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_combined = pd.read_csv('./weather/2020/SNOW_with_headers.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe69de54-bedc-4044-aea0-b26021f56e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>element</th>\n",
       "      <th>value</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BF1BI000001</th>\n",
       "      <td>20200716</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>900</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BF1EX000001</th>\n",
       "      <td>20200107</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>800</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BF1EX000001</th>\n",
       "      <td>20200108</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>800</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BF1EX000001</th>\n",
       "      <td>20200114</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>800</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BF1EX000001</th>\n",
       "      <td>20200115</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>800</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  date  element  value  M-FLAG Q-FLAG  S-FLAG OBS-TIME\n",
       "BF1BI000001  20200716  SNOW        0    NaN     NaN      N     900       BH\n",
       "BF1EX000001  20200107  SNOW        0    NaN     NaN      N     800       BH\n",
       "BF1EX000001  20200108  SNOW        0    NaN     NaN      N     800       BH\n",
       "BF1EX000001  20200114  SNOW        0    NaN     NaN      N     800       BH\n",
       "BF1EX000001  20200115  SNOW        0    NaN     NaN      N     800       BH"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cf788-ce94-43e1-a62b-870e321717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_2020['element'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85804308-4e9a-485c-af82-cede8d9b5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "prefix = 'sagemaker/weather-predictions/input'\n",
    "sess   = sagemaker.Session()\n",
    "\n",
    "uri = sess.upload_data(path=\"./weather/2022.csv\", key_prefix=prefix)\n",
    "print(uri)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
