{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e08d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8adc4",
   "metadata": {},
   "source": [
    "# Cost Predictions on AWS\n",
    "\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ce.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a59e0",
   "metadata": {},
   "source": [
    "## Get the Cost Data from AWS and save it a CSV in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43920699",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_cost_data_from_aws(start_date, end_date):\n",
    "    client = boto3.client('ce')\n",
    "    results = client.get_cost_and_usage(\n",
    "        TimePeriod={\n",
    "            'Start': start_date,\n",
    "            'End': datetime.now().strftime('%Y-%m-%d')\n",
    "            },\n",
    "            Granularity='DAILY',\n",
    "            Metrics=[\n",
    "                'UnblendedCost',\n",
    "            ],\n",
    "            GroupBy=[\n",
    "                {\n",
    "                    'Type': 'DIMENSION',\n",
    "                    'Key': 'SERVICE'\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    return results\n",
    "\n",
    "def get_cost_data_to_pandas(start_date, end_date):\n",
    "    results = get_cost_data_from_aws(start_date, end_date)\n",
    "    \n",
    "    start_date_list = []\n",
    "    cost_list = []\n",
    "    service_list = []\n",
    "\n",
    "    for item in results['ResultsByTime']:\n",
    "        for i in item['Groups']:\n",
    "            start_date_list.append(item['TimePeriod']['Start'])\n",
    "        service_list = service_list + [i['Keys'][0] for i in item['Groups']]\n",
    "        cost_list = cost_list + [i['Metrics']['UnblendedCost']['Amount'] for i in item['Groups']]\n",
    "    df = pd.DataFrame(list(zip(start_date_list, cost_list, service_list)), \n",
    "                      columns =['start_date', 'costs', 'service'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2e70b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2022-01-01'  ## This is the month that class started\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "my_cost_data = get_cost_data_to_pandas(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "767bff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_s3(df, end_date):\n",
    "    '''\n",
    "    Upload the CSV to S3\n",
    "    '''\n",
    "    # save the df as a csv\n",
    "    csv = f'cost_data_to_{end_date}.csv'\n",
    "    df.to_csv(csv, index=False)\n",
    "    \n",
    "    # set up the session\n",
    "    client = boto3.client('s3')\n",
    "\n",
    "    # upload the file\n",
    "    bucket = 'cost-management-robords'\n",
    "    print(f'getting file from {csv}')\n",
    "    key = f'by_service/{csv}'\n",
    "    with open(csv, \"rb\") as f:\n",
    "        client.upload_fileobj(f, bucket, key)\n",
    "\n",
    "    # Remove the file from the local filesystem\n",
    "    command_to_run_rm = [\"rm\", csv]\n",
    "    output_rm = subprocess.check_output(command_to_run_rm).decode(\"utf-8\").strip()\n",
    "    print(output_rm)\n",
    "\n",
    "    print('File uploaded to S3')\n",
    "    \n",
    "    return bucket, key, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c05de5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting file from cost_data_to_2022-11-10.csv\n",
      "\n",
      "File uploaded to S3\n"
     ]
    }
   ],
   "source": [
    "bucket, key, csv = save_to_s3(my_cost_data, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84245da",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "342dd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cost_forecast:\n",
    "    \n",
    "    def __init__(self, s3_path, dataset_name = 'Cost_Dataset',\n",
    "                import_job_name = \"Cost_Prediction_Import_Job\", dataset_group_name = \"Cost_Forecast\",\n",
    "                forecast_horizon = 30, forecast_frequency = \"1D\", predictor_name = \"Cost_Predictor\",\n",
    "                forecast_name = \"Cost_Forecast\"):\n",
    "        \n",
    "        self.s3_path = s3_path\n",
    "        self.role = boto3.client('iam').get_role(RoleName='ForecastNotebookRole')\n",
    "        self.role_arn = self.role['Role']['Arn']\n",
    "        \n",
    "        self.client = boto3.client('forecast')\n",
    "        \n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_arn = self.create_dataset()\n",
    "        \n",
    "        while self.check_status('dataset') != 'ACTIVE':\n",
    "            clear_output(wait=True)\n",
    "            self.check_status('dataset')\n",
    "            \n",
    "        self.import_job_name = import_job_name\n",
    "        self.dataset_import_job_arn = self.import_dataset()\n",
    "        \n",
    "        self.dataset_group_name = dataset_group_name\n",
    "        self.dataset_group_arn = self.dataset_group()\n",
    "        \n",
    "        while self.check_status('import') != 'ACTIVE':\n",
    "            clear_output(wait=True)\n",
    "            self.check_status('import')\n",
    "        \n",
    "        self.forecast_name = forecast_name\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.forecast_frequency = forecast_frequency\n",
    "        self.predictor_name = predictor_name\n",
    "        self.predictor_arn = self.train_predictor()\n",
    "        \n",
    "        while self.check_status('predictor') != 'ACTIVE':\n",
    "            clear_output(wait=True)\n",
    "            self.check_status('predictor')\n",
    "        \n",
    "        self.forecast = forecast_name\n",
    "        self.forecast_arn = self.create_forecast()\n",
    "        \n",
    "    \n",
    "    def create_dataset(self):\n",
    "        dataset_dicts = self.client.list_datasets()['Datasets']\n",
    "\n",
    "        if self.dataset_name in [i['DatasetName'] for i in self.client.list_datasets()['Datasets']]:\n",
    "            print('Dataset Already Exists')\n",
    "            ts_dataset_arn = ([item for item in dataset_dicts if \n",
    "                               item[\"DatasetName\"] == self.dataset_name][0]['DatasetArn'])\n",
    "        else:\n",
    "            print('Creating New Dataset')\n",
    "            schema = {\n",
    "               \"Attributes\":[\n",
    "                  {\n",
    "                     \"AttributeName\":\"timestamp\",\n",
    "                     \"AttributeType\":\"timestamp\"\n",
    "                  },\n",
    "                  {\n",
    "                     \"AttributeName\":\"target_value\",\n",
    "                     \"AttributeType\":\"float\"\n",
    "                  },\n",
    "                  {\n",
    "                     \"AttributeName\":\"item_id\",\n",
    "                     \"AttributeType\":\"string\"\n",
    "                  }\n",
    "               ]\n",
    "            }\n",
    "\n",
    "            # check if the dataset is created first:\n",
    "\n",
    "            create_dataset_response = self.client.create_dataset(\n",
    "                DatasetName=self.dataset_name,\n",
    "                Domain='CUSTOM',\n",
    "                DatasetType='TARGET_TIME_SERIES',\n",
    "                DataFrequency='1D',\n",
    "                Schema=schema\n",
    "            )\n",
    "            ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "            print('Dataset Create Initiated')\n",
    "        \n",
    "        return ts_dataset_arn\n",
    "    \n",
    "    def import_dataset(self):\n",
    "        TIMESTAMP_FORMAT = \"yyyy-MM-dd\"\n",
    "        TIMEZONE = \"UTC\"\n",
    "\n",
    "        import_job = self.client.list_dataset_import_jobs(\n",
    "            Filters=[\n",
    "                {\n",
    "                    'Key': 'DatasetArn',\n",
    "                    'Value': self.dataset_arn,\n",
    "                    'Condition': 'IS'\n",
    "                },\n",
    "            ]\n",
    "        )   \n",
    "\n",
    "        if self.import_job_name in [i['DatasetImportJobName'] for i in import_job['DatasetImportJobs']]:\n",
    "            print('Already Exists')\n",
    "            ts_dataset_import_job_arn = [item for item in import_job['DatasetImportJobs'] if item[\"DatasetImportJobName\"] == self.import_job_name][0]['DatasetImportJobArn']\n",
    "        else:\n",
    "            ts_dataset_import_job_response = \\\n",
    "                self.client.create_dataset_import_job(DatasetImportJobName=self.import_job_name,\n",
    "                                                   DatasetArn=self.dataset_arn,\n",
    "                                                   DataSource= {\n",
    "                                                     \"S3Config\" : {\n",
    "                                                         \"Path\": self.s3_path,\n",
    "                                                         \"RoleArn\": self.role_arn\n",
    "                                                     } \n",
    "                                                   },\n",
    "                                                   TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                                   TimeZone = TIMEZONE)\n",
    "\n",
    "            ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "            describe_dataset_import_job_response = self.client.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "            print(f\"Waiting for Dataset Import Job with ARNto become ACTIVE. This process could take 5-10 minutes.\")\n",
    "        return ts_dataset_import_job_arn\n",
    "    \n",
    "    def dataset_group(self):\n",
    "        DATASET_ARNS = [self.dataset_arn]\n",
    "        \n",
    "        if self.dataset_group_name in [i['DatasetGroupName'] for i in self.client.list_dataset_groups()['DatasetGroups']]:\n",
    "            print('Already Exists')\n",
    "            dataset_group_arn = ([item for item in self.client.list_dataset_groups()['DatasetGroups'] \n",
    "                                 if item[\"DatasetGroupName\"] == self.dataset_group_name][0]['DatasetGroupArn'])\n",
    "        else:\n",
    "            create_dataset_group_response = \\\n",
    "                self.client.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                              DatasetGroupName=self.dataset_group_name,\n",
    "                                              DatasetArns=DATASET_ARNS)\n",
    "\n",
    "            dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "            describe_dataset_group_response = self.client.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "\n",
    "            print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")\n",
    "    \n",
    "        return dataset_group_arn\n",
    "    \n",
    "    def train_predictor(self):\n",
    "        \n",
    "        if self.predictor_name in [i['PredictorName'] for i in self.client.list_predictors()['Predictors']]:\n",
    "            print('Already Exists')\n",
    "            predictor_arn = ([item for item in self.client.list_predictors()['Predictors'] \n",
    "                                 if item[\"PredictorName\"] == self.predictor_name][0]['PredictorArn'])\n",
    "        else:\n",
    "            create_auto_predictor_response = \\\n",
    "                self.client.create_auto_predictor(PredictorName = self.predictor_name,\n",
    "                                               ForecastHorizon = self.forecast_horizon,\n",
    "                                               ForecastFrequency = self.forecast_frequency,\n",
    "                                               DataConfig = {\n",
    "                                                   'DatasetGroupArn': self.dataset_group_arn\n",
    "                                                })\n",
    "\n",
    "            predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "            print(f\"Waiting for Predictor with ARN to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE\")\n",
    "        return predictor_arn\n",
    "    \n",
    "    def create_forecast(self):\n",
    "        \n",
    "        if self.forecast_name in [i['ForecastName'] for i in self.client.list_forecasts()['Forecasts']]:\n",
    "            print('Already Exists')\n",
    "            forecast_arn = ([item for item in self.client.list_forecasts()['Forecasts'] \n",
    "                                 if item[\"ForecastName\"] == self.forecast_name][0]['ForecastArn'])\n",
    "        else:\n",
    "\n",
    "            create_forecast_response = \\\n",
    "                self.client.create_forecast(ForecastName=self.forecast_name,\n",
    "                                         PredictorArn=self.predictor_arn)\n",
    "\n",
    "            forecast_arn = create_forecast_response['ForecastArn']\n",
    "            print(f\"Waiting for Forecast to become ACTIVE. Depending on data size and predictor settings，it can take several hours to be ACTIVE.\")\n",
    "\n",
    "        return forecast_arn\n",
    "    \n",
    "    def check_status(self, describe_type):\n",
    "        if describe_type == 'dataset':\n",
    "            describe_dataset_response = self.client.describe_dataset(DatasetArn=self.dataset_arn)\n",
    "            print(f\"The Dataset is now {describe_dataset_response['Status']}.\")\n",
    "            return describe_dataset_response['Status']\n",
    "        \n",
    "        elif describe_type == 'import':\n",
    "            status = self.client.describe_dataset_import_job(DatasetImportJobArn=self.dataset_import_job_arn)\n",
    "            print(status['DatasetImportJobName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {status[\"Status\"]}')\n",
    "            return status[\"Status\"]\n",
    "        \n",
    "        elif describe_type == 'predictor':\n",
    "            pred_status = self.client.describe_auto_predictor(PredictorArn=self.predictor_arn)\n",
    "            print(pred_status['PredictorName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {pred_status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {pred_status[\"Status\"]}')\n",
    "            return pred_status[\"Status\"]\n",
    "        \n",
    "        elif describe_type == 'forecast':\n",
    "            forecast_status = self.client.describe_forecast(ForecastArn=self.forecast_arn)\n",
    "            print(forecast_status['ForecastName'])\n",
    "            try:\n",
    "                print(f'Time Remaining in Minutes (estimated): {forecast_status[\"EstimatedTimeRemainingInMinutes\"]}')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'Status: {forecast_status[\"Status\"]}')\n",
    "            \n",
    "            return forecast_status[\"Status\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bdd4cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = 's3://'+bucket+'/'+key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39cf6a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Already Exists\n",
      "The Dataset is now ACTIVE.\n",
      "Already Exists\n",
      "Already Exists\n",
      "Cost_Prediction_Import_Jobv3\n",
      "Status: ACTIVE\n",
      "Already Exists\n",
      "Cost_Predictorv3\n",
      "Status: ACTIVE\n",
      "Waiting for Forecast to become ACTIVE. Depending on data size and predictor settings，it can take several hours to be ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "cost_forecast_output = cost_forecast(s3_path = s3_path, dataset_name = 'Cost_Datasetv3',\n",
    "                import_job_name = \"Cost_Prediction_Import_Jobv3\", dataset_group_name = \"Cost_Forecastv3\",\n",
    "                forecast_horizon = 30, forecast_frequency = \"1D\", predictor_name = \"Cost_Predictorv3\",\n",
    "                forecast_name = \"Cost_Forecastv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b0622",
   "metadata": {},
   "source": [
    "## Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c106084",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastquery = boto3.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc2354bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = boto3.client('iam').get_role(RoleName='ForecastNotebookRole')\n",
    "role_arn = role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ca472f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('forecast')\n",
    "\n",
    "response = client.create_forecast_export_job(\n",
    "    ForecastExportJobName='CostForecastNovResults',\n",
    "    ForecastArn=cost_forecast_output.forecast_arn,\n",
    "    Destination={\n",
    "        'S3Config': {\n",
    "            'Path': 's3://cost-management-robords/forecast_results/',\n",
    "            'RoleArn': role_arn\n",
    "        }\n",
    "    },\n",
    "    Format='CSV'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8307b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ForecastExportJobArn': 'arn:aws:forecast:us-east-1:669437599565:forecast-export-job/Cost_Forecastv3/CostForecastNovResults',\n",
       " 'ResponseMetadata': {'RequestId': '6893f7f9-85e7-48a0-a44b-be7013a976b7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 11 Nov 2022 22:24:13 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '125',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '6893f7f9-85e7-48a0-a44b-be7013a976b7'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "875953e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_s3(bucket, path):\n",
    "    '''\n",
    "    Get the list of files from S3\n",
    "    \n",
    "    If we wanted to just list items in the bucket, we could do the following.  \n",
    "    However, we can't check the file has content with this\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    for file in my_bucket.objects.all():\n",
    "        print(file.key)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=path\n",
    "    )\n",
    "\n",
    "    most_recent_file_date = max([i['LastModified'] for i in response['Contents']])\n",
    "    most_recent_file_key = ([i['Key'] for i in response['Contents'] \n",
    "                         if i['LastModified'] == most_recent_file_date][0])\n",
    "    \n",
    "    return response, most_recent_file_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20525c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_from_s3(bucket, path):\n",
    "    \n",
    "    _, key = list_files_in_s3(bucket, path)\n",
    "    \n",
    "    print(key)\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    df = pd.read_csv(response.get('Body'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af5b9a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_service/cost_data_to_2022-11-10.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Services</th>\n",
       "      <th>Routes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWS CloudTrail</td>\n",
       "      <td>/costs/AWS CloudTrail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AWS Glue</td>\n",
       "      <td>/costs/AWS Glue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Elastic File System</td>\n",
       "      <td>/costs/Amazon Elastic File System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon GuardDuty</td>\n",
       "      <td>/costs/Amazon GuardDuty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Simple Storage Service</td>\n",
       "      <td>/costs/Amazon Simple Storage Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AmazonCloudWatch</td>\n",
       "      <td>/costs/AmazonCloudWatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AWS Key Management Service</td>\n",
       "      <td>/costs/AWS Key Management Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon Glacier</td>\n",
       "      <td>/costs/Amazon Glacier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon Simple Notification Service</td>\n",
       "      <td>/costs/Amazon Simple Notification Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Simple Queue Service</td>\n",
       "      <td>/costs/Amazon Simple Queue Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AWS Secrets Manager</td>\n",
       "      <td>/costs/AWS Secrets Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CloudWatch Events</td>\n",
       "      <td>/costs/CloudWatch Events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EC2 - Other</td>\n",
       "      <td>/costs/EC2 - Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amazon Elastic Compute Cloud - Compute</td>\n",
       "      <td>/costs/Amazon Elastic Compute Cloud - Compute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Amazon Elastic Load Balancing</td>\n",
       "      <td>/costs/Amazon Elastic Load Balancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AWS Service Catalog</td>\n",
       "      <td>/costs/AWS Service Catalog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amazon Elastic MapReduce</td>\n",
       "      <td>/costs/Amazon Elastic MapReduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>/costs/Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CodeBuild</td>\n",
       "      <td>/costs/CodeBuild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AWS CodeArtifact</td>\n",
       "      <td>/costs/AWS CodeArtifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AWS CodeCommit</td>\n",
       "      <td>/costs/AWS CodeCommit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amazon Forecast</td>\n",
       "      <td>/costs/Amazon Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AWS Lambda</td>\n",
       "      <td>/costs/AWS Lambda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amazon API Gateway</td>\n",
       "      <td>/costs/Amazon API Gateway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Amazon Cognito</td>\n",
       "      <td>/costs/Amazon Cognito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Amazon DynamoDB</td>\n",
       "      <td>/costs/Amazon DynamoDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AWS Cost Explorer</td>\n",
       "      <td>/costs/AWS Cost Explorer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Services  \\\n",
       "0                           AWS CloudTrail   \n",
       "1                                 AWS Glue   \n",
       "2               Amazon Elastic File System   \n",
       "3                         Amazon GuardDuty   \n",
       "4            Amazon Simple Storage Service   \n",
       "5                         AmazonCloudWatch   \n",
       "6               AWS Key Management Service   \n",
       "7                           Amazon Glacier   \n",
       "8       Amazon Simple Notification Service   \n",
       "9              Amazon Simple Queue Service   \n",
       "10                     AWS Secrets Manager   \n",
       "11                       CloudWatch Events   \n",
       "12                             EC2 - Other   \n",
       "13  Amazon Elastic Compute Cloud - Compute   \n",
       "14           Amazon Elastic Load Balancing   \n",
       "15                     AWS Service Catalog   \n",
       "16                Amazon Elastic MapReduce   \n",
       "17                        Amazon SageMaker   \n",
       "18                               CodeBuild   \n",
       "19                        AWS CodeArtifact   \n",
       "20                          AWS CodeCommit   \n",
       "21                         Amazon Forecast   \n",
       "22                              AWS Lambda   \n",
       "23                      Amazon API Gateway   \n",
       "24                          Amazon Cognito   \n",
       "25                         Amazon DynamoDB   \n",
       "26                       AWS Cost Explorer   \n",
       "\n",
       "                                           Routes  \n",
       "0                           /costs/AWS CloudTrail  \n",
       "1                                 /costs/AWS Glue  \n",
       "2               /costs/Amazon Elastic File System  \n",
       "3                         /costs/Amazon GuardDuty  \n",
       "4            /costs/Amazon Simple Storage Service  \n",
       "5                         /costs/AmazonCloudWatch  \n",
       "6               /costs/AWS Key Management Service  \n",
       "7                           /costs/Amazon Glacier  \n",
       "8       /costs/Amazon Simple Notification Service  \n",
       "9              /costs/Amazon Simple Queue Service  \n",
       "10                     /costs/AWS Secrets Manager  \n",
       "11                       /costs/CloudWatch Events  \n",
       "12                             /costs/EC2 - Other  \n",
       "13  /costs/Amazon Elastic Compute Cloud - Compute  \n",
       "14           /costs/Amazon Elastic Load Balancing  \n",
       "15                     /costs/AWS Service Catalog  \n",
       "16                /costs/Amazon Elastic MapReduce  \n",
       "17                        /costs/Amazon SageMaker  \n",
       "18                               /costs/CodeBuild  \n",
       "19                        /costs/AWS CodeArtifact  \n",
       "20                          /costs/AWS CodeCommit  \n",
       "21                         /costs/Amazon Forecast  \n",
       "22                              /costs/AWS Lambda  \n",
       "23                      /costs/Amazon API Gateway  \n",
       "24                          /costs/Amazon Cognito  \n",
       "25                         /costs/Amazon DynamoDB  \n",
       "26                       /costs/AWS Cost Explorer  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = 'cost-management-robords'\n",
    "path = 'by_service'\n",
    "services = get_file_from_s3(bucket, path)['service']\n",
    "services = services.unique()\n",
    "service_list = list(services)\n",
    "route_list = [f'/costs/{i}' for i in service_list]\n",
    "\n",
    "pd.DataFrame(list(zip(service_list, route_list)), columns=['Services','Routes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a1870de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_results/CostForecastNovResults_2022-11-11T22-38-05Z_part0.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p10</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon simple notification service</td>\n",
       "      <td>2022-11-10T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon simple notification service</td>\n",
       "      <td>2022-11-11T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon simple notification service</td>\n",
       "      <td>2022-11-12T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon simple notification service</td>\n",
       "      <td>2022-11-13T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon simple notification service</td>\n",
       "      <td>2022-11-14T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>amazon simple queue service</td>\n",
       "      <td>2022-12-05T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>amazon simple queue service</td>\n",
       "      <td>2022-12-06T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>amazon simple queue service</td>\n",
       "      <td>2022-12-07T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>amazon simple queue service</td>\n",
       "      <td>2022-12-08T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>amazon simple queue service</td>\n",
       "      <td>2022-12-09T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                item_id                  date  p10  p50  p90\n",
       "0    amazon simple notification service  2022-11-10T00:00:00Z  0.0  0.0  0.0\n",
       "1    amazon simple notification service  2022-11-11T00:00:00Z  0.0  0.0  0.0\n",
       "2    amazon simple notification service  2022-11-12T00:00:00Z  0.0  0.0  0.0\n",
       "3    amazon simple notification service  2022-11-13T00:00:00Z  0.0  0.0  0.0\n",
       "4    amazon simple notification service  2022-11-14T00:00:00Z  0.0  0.0  0.0\n",
       "..                                  ...                   ...  ...  ...  ...\n",
       "175         amazon simple queue service  2022-12-05T00:00:00Z  0.0  0.0  0.0\n",
       "176         amazon simple queue service  2022-12-06T00:00:00Z  0.0  0.0  0.0\n",
       "177         amazon simple queue service  2022-12-07T00:00:00Z  0.0  0.0  0.0\n",
       "178         amazon simple queue service  2022-12-08T00:00:00Z  0.0  0.0  0.0\n",
       "179         amazon simple queue service  2022-12-09T00:00:00Z  0.0  0.0  0.0\n",
       "\n",
       "[180 rows x 5 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = 'cost-management-robords'\n",
    "path = 'forecast_results'\n",
    "get_file_from_s3(bucket, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "665d992a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Forecast': {'Predictions': {'p10': [{'Timestamp': '2022-11-10T00:00:00',\n",
       "     'Value': 0.008939661126829215},\n",
       "    {'Timestamp': '2022-11-11T00:00:00', 'Value': 0.009371761048774931},\n",
       "    {'Timestamp': '2022-11-12T00:00:00', 'Value': 0.011102962392173807},\n",
       "    {'Timestamp': '2022-11-13T00:00:00', 'Value': 0.008949113410965173},\n",
       "    {'Timestamp': '2022-11-14T00:00:00', 'Value': 0.007664827647221533},\n",
       "    {'Timestamp': '2022-11-15T00:00:00', 'Value': 0.007734930256903579},\n",
       "    {'Timestamp': '2022-11-16T00:00:00', 'Value': 0.007325832305530203},\n",
       "    {'Timestamp': '2022-11-17T00:00:00', 'Value': 0.007044587888077485},\n",
       "    {'Timestamp': '2022-11-18T00:00:00', 'Value': 0.0074160634941466096},\n",
       "    {'Timestamp': '2022-11-19T00:00:00', 'Value': 0.008810191058688056},\n",
       "    {'Timestamp': '2022-11-20T00:00:00', 'Value': 0.007112682785308439},\n",
       "    {'Timestamp': '2022-11-21T00:00:00', 'Value': 0.006096280855539102},\n",
       "    {'Timestamp': '2022-11-22T00:00:00', 'Value': 0.006151641801450916},\n",
       "    {'Timestamp': '2022-11-23T00:00:00', 'Value': 0.005821952325274221},\n",
       "    {'Timestamp': '2022-11-24T00:00:00', 'Value': 0.005590854208103261},\n",
       "    {'Timestamp': '2022-11-25T00:00:00', 'Value': 0.005874370449588169},\n",
       "    {'Timestamp': '2022-11-26T00:00:00', 'Value': 0.006961547824671349},\n",
       "    {'Timestamp': '2022-11-27T00:00:00', 'Value': 0.005603526546053717},\n",
       "    {'Timestamp': '2022-11-28T00:00:00', 'Value': 0.004786064595332798},\n",
       "    {'Timestamp': '2022-11-29T00:00:00', 'Value': 0.00481024983231324},\n",
       "    {'Timestamp': '2022-11-30T00:00:00', 'Value': 0.004531912291649839},\n",
       "    {'Timestamp': '2022-12-01T00:00:00', 'Value': 0.004330041169167478},\n",
       "    {'Timestamp': '2022-12-02T00:00:00', 'Value': 0.004524100116280745},\n",
       "    {'Timestamp': '2022-12-03T00:00:00', 'Value': 0.0053281282869060195},\n",
       "    {'Timestamp': '2022-12-04T00:00:00', 'Value': 0.004259430439467653},\n",
       "    {'Timestamp': '2022-12-05T00:00:00', 'Value': 0.0036107002114116396},\n",
       "    {'Timestamp': '2022-12-06T00:00:00', 'Value': 0.0035989732442896025},\n",
       "    {'Timestamp': '2022-12-07T00:00:00', 'Value': 0.0033599630171764604},\n",
       "    {'Timestamp': '2022-12-08T00:00:00', 'Value': 0.0031782739956646485},\n",
       "    {'Timestamp': '2022-12-09T00:00:00', 'Value': 0.003284287557044104}],\n",
       "   'p50': [{'Timestamp': '2022-11-10T00:00:00', 'Value': 0.01233371063240012},\n",
       "    {'Timestamp': '2022-11-11T00:00:00', 'Value': 0.013413010409863427},\n",
       "    {'Timestamp': '2022-11-12T00:00:00', 'Value': 0.01646140765214016},\n",
       "    {'Timestamp': '2022-11-13T00:00:00', 'Value': 0.013730843296379358},\n",
       "    {'Timestamp': '2022-11-14T00:00:00', 'Value': 0.01216185760058615},\n",
       "    {'Timestamp': '2022-11-15T00:00:00', 'Value': 0.012685851062656342},\n",
       "    {'Timestamp': '2022-11-16T00:00:00', 'Value': 0.012414954877734294},\n",
       "    {'Timestamp': '2022-11-17T00:00:00', 'Value': 0.012333735421109122},\n",
       "    {'Timestamp': '2022-11-18T00:00:00', 'Value': 0.013413037367785647},\n",
       "    {'Timestamp': '2022-11-19T00:00:00', 'Value': 0.016461440736834313},\n",
       "    {'Timestamp': '2022-11-20T00:00:00', 'Value': 0.013730870893092868},\n",
       "    {'Timestamp': '2022-11-21T00:00:00', 'Value': 0.012161882043899114},\n",
       "    {'Timestamp': '2022-11-22T00:00:00', 'Value': 0.012685876559109096},\n",
       "    {'Timestamp': '2022-11-23T00:00:00', 'Value': 0.01241497982973073},\n",
       "    {'Timestamp': '2022-11-24T00:00:00', 'Value': 0.012333760209867945},\n",
       "    {'Timestamp': '2022-11-25T00:00:00', 'Value': 0.013413064325762046},\n",
       "    {'Timestamp': '2022-11-26T00:00:00', 'Value': 0.016461473821594963},\n",
       "    {'Timestamp': '2022-11-27T00:00:00', 'Value': 0.013730898489861842},\n",
       "    {'Timestamp': '2022-11-28T00:00:00', 'Value': 0.012161906487261204},\n",
       "    {'Timestamp': '2022-11-29T00:00:00', 'Value': 0.012685902055613095},\n",
       "    {'Timestamp': '2022-11-30T00:00:00', 'Value': 0.012415004781777315},\n",
       "    {'Timestamp': '2022-12-01T00:00:00', 'Value': 0.01233378499867659},\n",
       "    {'Timestamp': '2022-12-02T00:00:00', 'Value': 0.013413091283792627},\n",
       "    {'Timestamp': '2022-12-03T00:00:00', 'Value': 0.016461506906422105},\n",
       "    {'Timestamp': '2022-12-04T00:00:00', 'Value': 0.01373092608668628},\n",
       "    {'Timestamp': '2022-12-05T00:00:00', 'Value': 0.01216193093067242},\n",
       "    {'Timestamp': '2022-12-06T00:00:00', 'Value': 0.012685927552168337},\n",
       "    {'Timestamp': '2022-12-07T00:00:00', 'Value': 0.01241502973387405},\n",
       "    {'Timestamp': '2022-12-08T00:00:00', 'Value': 0.012333809787535056},\n",
       "    {'Timestamp': '2022-12-09T00:00:00', 'Value': 0.013413118241877388}],\n",
       "   'p90': [{'Timestamp': '2022-11-10T00:00:00', 'Value': 0.015727760137971024},\n",
       "    {'Timestamp': '2022-11-11T00:00:00', 'Value': 0.017454259770951924},\n",
       "    {'Timestamp': '2022-11-12T00:00:00', 'Value': 0.02181985291210651},\n",
       "    {'Timestamp': '2022-11-13T00:00:00', 'Value': 0.018512573181793543},\n",
       "    {'Timestamp': '2022-11-14T00:00:00', 'Value': 0.016658887553950768},\n",
       "    {'Timestamp': '2022-11-15T00:00:00', 'Value': 0.017636771868409104},\n",
       "    {'Timestamp': '2022-11-16T00:00:00', 'Value': 0.017504077449938385},\n",
       "    {'Timestamp': '2022-11-17T00:00:00', 'Value': 0.01762288295414076},\n",
       "    {'Timestamp': '2022-11-18T00:00:00', 'Value': 0.019410011241424684},\n",
       "    {'Timestamp': '2022-11-19T00:00:00', 'Value': 0.02411269041498057},\n",
       "    {'Timestamp': '2022-11-20T00:00:00', 'Value': 0.020349059000877297},\n",
       "    {'Timestamp': '2022-11-21T00:00:00', 'Value': 0.018227483232259124},\n",
       "    {'Timestamp': '2022-11-22T00:00:00', 'Value': 0.019220111316767277},\n",
       "    {'Timestamp': '2022-11-23T00:00:00', 'Value': 0.01900800733418724},\n",
       "    {'Timestamp': '2022-11-24T00:00:00', 'Value': 0.019076666211632627},\n",
       "    {'Timestamp': '2022-11-25T00:00:00', 'Value': 0.020951758201935924},\n",
       "    {'Timestamp': '2022-11-26T00:00:00', 'Value': 0.025961399818518575},\n",
       "    {'Timestamp': '2022-11-27T00:00:00', 'Value': 0.021858270433669967},\n",
       "    {'Timestamp': '2022-11-28T00:00:00', 'Value': 0.01953774837918961},\n",
       "    {'Timestamp': '2022-11-29T00:00:00', 'Value': 0.02056155427891295},\n",
       "    {'Timestamp': '2022-11-30T00:00:00', 'Value': 0.02029809727190479},\n",
       "    {'Timestamp': '2022-12-01T00:00:00', 'Value': 0.0203375288281857},\n",
       "    {'Timestamp': '2022-12-02T00:00:00', 'Value': 0.02230208245130451},\n",
       "    {'Timestamp': '2022-12-03T00:00:00', 'Value': 0.02759488552593819},\n",
       "    {'Timestamp': '2022-12-04T00:00:00', 'Value': 0.02320242173390491},\n",
       "    {'Timestamp': '2022-12-05T00:00:00', 'Value': 0.020713161649933202},\n",
       "    {'Timestamp': '2022-12-06T00:00:00', 'Value': 0.02177288186004707},\n",
       "    {'Timestamp': '2022-12-07T00:00:00', 'Value': 0.021470096450571637},\n",
       "    {'Timestamp': '2022-12-08T00:00:00', 'Value': 0.02148934557940546},\n",
       "    {'Timestamp': '2022-12-09T00:00:00', 'Value': 0.023541948926710674}]}},\n",
       " 'ResponseMetadata': {'RequestId': '3eb2cb1f-937b-4cd3-a81e-4f937ea35207',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 11 Nov 2022 22:15:25 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '5887',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '3eb2cb1f-937b-4cd3-a81e-4f937ea35207'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastquery.query_forecast(\n",
    "    ForecastArn=cost_forecast_output.forecast_arn,\n",
    "    Filters={\"item_id\": 'Amazon Simple Storage Service'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206a469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
